---
title: "The 37 Implementation Details of Proximal Policy Optimization"
publishDate: 2022-04-27T00:00:00
draft: false

# Is this a selected publication? (true/false)
featured: false

authors:
- Shengyi Huang
- Rousslan Fernand Julien Dossa
- admin
- Anssi Kanervisto
- Weixun Wang


# Publication type.
# Legend: 0 = Uncategorized; 1 = Conference paper; 2 = Journal article;
# 3 = Preprint / Working Paper; 4 = Report; 5 = Book; 6 = Book section;
# 7 = Thesis; 8 = Patent
publication_types: ["1"]

# Publication name and optional abbreviated version.
publication: "10th International Conference on Learning Representations"
publication_short: "ICLR Blog Track, 2022"

# Abstract and optional shortened version.
abstract: "Proximal policy optimization (PPO) has become one of the most popular deep reinforcement learning (DRL) algorithms. Yet, reproducing the PPO's results has been challenging in the community.  While recent works conducted ablation studies to provide insight on PPO's implementation details, these works are not structured as tutorials and only focus on details concerning robotics tasks. As a result, reproducing PPO from scratch can become a daunting experience. Instead of introducing additional improvements, or doing further ablation studies, this blog post takes a step back and focuses on delivering a thorough reproduction of PPO in all accounts, as well as aggregating, documenting, and cataloging its most salient implementation details. This blog post also points out software engineering challenges in PPO and further efficiency improvement via the accelerated vectorized environments. With these, we believe this blog post will help people understand PPO faster and better, facilitating customization and research upon this versatile RL algorithm."

summary: ""

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.


# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `internal-project` references `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
projects: []

# Tags (optional).
#   Set `tags: []` for no tags, or use the form `tags: ["A Tag", "Another Tag"]` for one or more tags.
tags:
  - Reinforcement Learning,
  - Robotics

# Links (optional).
url_pdf: "https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/"
url_preprint: ""
url_code: "https://github.com/vwxyzjn/ppo-implementation-details"
url_dataset: ""
url_project: ""
url_slides: ""
url_video: "https://www.youtube.com/watch?v=MEt6rrxH8W4"
url_poster: ""
url_source: ""


# Digital Object Identifier (DOI)
doi: ""

---
